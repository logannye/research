{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNjHNmbYrEhlXgpys5QLpR8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/logannye/research/blob/main/Discharge_Notes2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model transforms clinical progress notes from patient profiles into vector embeddings. It is based upon the following model from HuggingFace:\n",
        "https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT"
      ],
      "metadata": {
        "id": "c_RwTu4V6SIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 1: Install the Transformers and Pandas libraries\n",
        "!pip install transformers pandas\n",
        "\n",
        "# Step 2: Import libraries\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Y0c3bCxQJG",
        "outputId": "4ca85a57-98d2-493f-9428-fea833a0d8a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the tokenizer and model for Bio_ClinicalBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "# Function to vectorize a single clinical note\n",
        "def vectorize_clinical_note(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "q_tb3kDWw_30"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the subject IDs for the two subsets using the correct paths\n",
        "pancan_subj_path = '/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/pancan_subj.npy'\n",
        "safe_subj_path = '/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/safe_subj.npy'"
      ],
      "metadata": {
        "id": "AGOvQCOu3xAi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pancan_subj = np.load(pancan_subj_path, allow_pickle=True).tolist()\n",
        "safe_subj = np.load(safe_subj_path, allow_pickle=True).tolist()"
      ],
      "metadata": {
        "id": "FN5G1UWTT1fc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the clinical notes DataFrame\n",
        "# Make sure to adjust the path below to where your discharge notes CSV file is located\n",
        "csv_file_path = '/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/discharge.csv'\n",
        "df_notes = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Assuming there's a column for clinical notes, replace 'note_text' with the actual column name\n",
        "note_column = 'text'  # Change this to the actual column name in your CSV\n",
        "\n",
        "# Filter the DataFrame for only the selected patients\n",
        "pancan_notes = df_notes[df_notes['subject_id'].isin(pancan_subj)]\n",
        "safe_notes = df_notes[df_notes['subject_id'].isin(safe_subj)]\n",
        "\n",
        "# Function to process and vectorize notes for a given DataFrame\n",
        "def process_and_vectorize_notes(df, note_column='text'):\n",
        "    vectors = []\n",
        "    for note in df[note_column]:\n",
        "        vectors.append(vectorize_clinical_note(note).numpy())  # Convert tensor to numpy array for easier handling\n",
        "    return np.array(vectors)\n",
        "\n",
        "# Vectorize notes for patients with pancreatic cancer\n",
        "pancan_vectors = process_and_vectorize_notes(pancan_notes, note_column)\n",
        "\n",
        "# Vectorize notes for control group patients\n",
        "safe_vectors = process_and_vectorize_notes(safe_notes, note_column)\n",
        "\n",
        "# Now pancan_vectors and safe_vectors contain the vector representations for the respective patient groups"
      ],
      "metadata": {
        "id": "8407tsi2_Iog"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Save the vectors to .npy files\n",
        "np.save('/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/pancan_vectors.npy', pancan_vectors)\n",
        "np.save('/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/safe_vectors.npy', safe_vectors)\n"
      ],
      "metadata": {
        "id": "ZLXOdGlbUVek"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the vector files"
      ],
      "metadata": {
        "id": "xxQA6oIVUX4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the saved .npy files\n",
        "files.download('/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/pancan_vectors.npy')\n",
        "files.download('/content/drive/MyDrive/Galen-Health/Datasets/mimic-iv-note/note/safe_vectors.npy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dD0NC6daUXZk",
        "outputId": "1df1c25a-a490-41bd-c52f-52b4009fe203"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e84674a7-9268-4417-b110-974604a61ad9\", \"pancan_vectors.npy\", 15418496)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_18d1a649-f67d-4664-b85e-b7d4768c1b7e\", \"safe_vectors.npy\", 9560192)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}